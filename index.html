<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>


<html>
<head>

	<title>This is my paper title</title>
	<meta property="og:image" content="Path to my teaser.pdf"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Semi-Supervised Learning of Monocular Depth Estimation
	via Consistency Regularization with K-way Disjoint Masking" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">Semi-Supervised Learning of Monocular Depth Estimation via Consistency Regularization with K-way Disjoint Masking</span>
		<table align=center width=900px>
			<table align=center width=900px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href=".">Jongbeom Baek<sup>1</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href=".">Gyeongnyeon Kim<sup>1</a></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href=".">Seonghoon Park<sup>1</a></span>
						</center>
					</td><td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href=".">Honggyu An<sup>1</a></span>
						</center>
					</td><td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://mattpoggi.github.io/">Matteo Poggi<sup>2</a></span>
						</center>
					</td><td align=center width=100px>
						<center>
							<span style="font-size:24px"><a href="https://cvlab.korea.ac.kr/members">Seungryong Kim<sup>1</a></span>
						</center>
					</td>
				</tr>
			</table>

			<table align=center width=800px>
				<tr>
					<td align=center width=150px>
						<center>
							<span style="font-size:20px">Korea University<sup>1</sup></a></span>
						</center>
					</td>
			
					<td align=center width=150px>
						<center>
							<span style="font-size:20px">University of Bologna<sup>2</sup></a></span>
						</center>
					</td>
				</tr>
			</table>
			
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/KU-CVLAB/K-way-masking-depth/tree/gh-pages'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=850px>
					<center>
						<img class="round" style="width:850px" src="./resources/KITTI_qual.png"/>
					</center>
						Qualitative results on the KITTI dataset. (a) RGB image, predicted depth maps by (b), (d) baseline, and (c), (e)
						ours using 100 and 10,000 labeled frames, respectively. <br><br>
					<center>
						<img class="round" style="width:850px" src="./resources/NYU_qual.png"/>
					</center>
						Qualitative results on the NYU-Depth-v2 dataset. (a) RGB image, (b) ground-truth depth map, and predicted depth
						maps by (c), (e) baseline, and (d), (f) ours using 100 and 10,000 labeled frames, respectively.
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				Semi-Supervised Learning (SSL) has recently accomplished successful achievements in various fields such as image classification, 
				object detection, and semantic segmentation, which typically require a lot of labour to construct ground-truth. Especially in the depth estimation task, 
				annotating training data is very costly and time-consuming, and thus recent SSL regime seems an attractive solution. 
				In this paper, for the first time, we introduce a novel framework for semi-supervised learning of monocular depth estimation networks, 
				using consistency regularization to mitigate the reliance on large ground-truth depth data. 
				We propose a novel data augmentation approach, called \(K\)-way disjoint masking, 
				which allows the network for learning how to reconstruct invisible regions so that the model not only becomes robust to perturbations 
				but also generates globally consistent output depth maps. Experiments on the KITTI and NYU-Depth-v2 datasets demonstrate the effectiveness of each component in our pipeline, 
				robustness to the use of fewer and fewer annotated images, and superior results compared to other state-of-the-art, semi-supervised methods for monocular depth estimation.
			</td>
		</tr>
	</table>

	<hr>

	<center><h1>Overview of our Framework</h1></center>

	<table align=center width=420px>
		<center>
			<tr>
				<td>
				</td>
			</tr>
		</center>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=1000px>
				<center>
					<td><img class="round" style="width:1000px" src="./resources/overview.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<center>
			<tr>
				<td>
					Our proposed method consists of two main components; a branch using full tokens (top), and a branch using \(K\)-way disjoint masked tokens (bottom), 
					where \(K\)-number of subsets are encoded independently and concatenated before decoding. 
					We use consistency loss \(\mathcal{L}_\mathrm{dc}\) to make predictions between original and augmented images consistent, 
					aided by an uncertainty measure. Feature consistency loss \(\mathcal{L}_\mathrm{fc}\) is also applied to facilitate the convergence.
				</td>
			</tr>
		</center>
	</table>

	<hr>

	<table align=center width=850px>
		<center><h1>Qualitative Results</h1></center>
		<center><h1><span style="font-size:25px">Sparsely Supervised Results on KITTI</span></h1></center>
		<table align=center width=420px></table>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/KITTI_sparse.png"/></td>
				</center>
			</td>
		</tr>
		</table>
		<table align=center width=850px>
			<center>
				<tr>
					<td>
						Quantitative results on the KITTI dataset in a sparsely-supervised setting. ‘Baseline’ only uses a sparse depth, and
						‘Self’ indicates existing self-supervised strategies. ‘Ours’ indicates the proposed semi-supervised learning framework.
						Our proposed method outperforms the baseline with any different number of data frames. 
						As this amount is decreased further, performance begins to degrade rapidly. 
						This is mostly due to the model's inability to learn the appropriate scale and structure of the scene with such sparse information. 
						However, as the labels become sparser, the performance degradation of our proposed method progresses more slowly 
						compared to the baseline or naive semi-supervised approach using self-supervised losses, and the performance gap gets larger.
					</td>
				</tr>
			</center>
		</table>
		<!-- <center><h1><span style="font-size:25px">Qualitative Results on KITTI</span></h1></center>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/KITTI_additional.png"/></td>
				</center>
			</td>
		</tr>
		<center><h1><span style="font-size:25px">Qualitative Supervised Results on KITTI</span></h1></center>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/NYU_additional.png"/></td>
				</center>
			</td>
		</tr> -->
		<center><h1><span style="font-size:25px">Domain Adoptation Result on vKITTI to KITTI</span></h1></center>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/domain_adopt.png"/></td>
				</center>
			</td>
		</tr>
		<table align=center width=850px>
			<center>
				<tr>
					<td>
						Qualitative results on the KITTI dataset. (a), (c) RGB image, and (b), (d) depth map. Our framework proves to
						work well in domain adaptation task on real-world images.
						We simply apply our framework to unsupervised domain adaptation methods using virtual KITTI (vKITTI) and KITTI as synthetic 
						and real datasets respectively. 
					</td>
				</tr>
			</center>
		</table>
	</table>

	<hr>
	<table align=center width=850px>
		<center><h1>Quantative Results</h1></center>
		<table align=center width=420px></table>
		<tr>
			<td align=center width=850px>
				<center>
					<td><img class="round" style="width:900px" src="./resources/Comparison.png"/></td>
				</center>
			</td>
		</tr>
		</table>
		<table align=center width=850px>
			<center>
				<tr>
					<td>
						Quantitative results. comparing our method against the existing approaches on the Eigen split of the KITTI dataset, using improved ground truth.
    					`Sup.', `Self.(M)', and `Self.(S)' indicate supervised, existing self-supervised strategies on video and stereo pairs, respectively. 
						`Self.' denotes our proposed consistency regularization, which needs no stereo images or video sequences. 
						`K', `C', and `F' indicate KITTI, Cityscapes, and FlyingThings3D, respectively. 'Mix' indicate the dataset proposed from <a href="https://arxiv.org/abs/2103.13413">DPT</a></span>, 
						which is approximately 60 times larger than KITTI, which contains 1.4\(M\) images (DB.). `\(\ast\)' denotes ran by ourselves.
					</td>
				</tr>
			</center>
		</table>
	</table>

	<hr>

	<table align=center width=450px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">J. Baek, G. Kim, S. Park,  <br> H. An, M. Poggi, S. Kim<br>
				<b>Semi-Supervised Learning of Monocular Depth Estimation
					via Consistency Regularization with K-way Disjoint Masking.</b><br>
				(hosted on <a href="">ArXiv</a>)<br>
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<br>
	<hr>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This research was supported in part by <a href="https://www.hyundaimotorgroup.com/tech/1075">Autonomous Driving Center</a>, R&D Division, Hyundai Motor Company.

					<br><br>
					
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.

				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

